{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3\n",
    "The question is about causal inference with a continuous response y, 0-1 valued treatment t, and\n",
    "confounders x = (x0, x1, x2, x3). The sample size n = 2000 and training data (yi, ti, xi) (i =\n",
    "1, . . . , n) are in files resp.csv, trt.csv, and conf.csv.\n",
    "1. (10 pts) Estimate the average treatment effect (ATE) using propensity scores. Employ logistic\n",
    "regression to estimate the propensity scores necessary for computing the ATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "y = np.array(pd.read_csv('resp.csv'))\n",
    "t = np.array(pd.read_csv('trt.csv'))\n",
    "X = np.array(pd.read_csv('conf.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27178862],\n",
       "       [-0.19972188],\n",
       "       [ 2.66125352],\n",
       "       ...,\n",
       "       [ 3.80922299],\n",
       "       [-0.60139812],\n",
       "       [ 4.23244633]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE using logistic regression propensity scores: -1.5174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PERFECT SOLUTION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit logistic regression\n",
    "logit = LogisticRegression(solver='lbfgs')\n",
    "logit.fit(X, t)\n",
    "\n",
    "# Estimate propensity scores\n",
    "p_score = logit.predict_proba(X)[:, 1]\n",
    "\n",
    "# Estimate ATE using propensity scores\n",
    "ate_logit = np.mean((t * y) / p_score) - np.mean(((1 - t) * y) / (1 - p_score))\n",
    "print(f\"ATE using logistic regression propensity scores: {ate_logit:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37769339, 0.88302675, 0.24605851, ..., 0.15517218, 0.68493871,\n",
       "       0.22510504])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (10 pts) Instead of logistic regression, use a deep neural network to estimate the propensity scores,\n",
    "and then compute the ATE. Compare the ATE estimate with the previous ATE estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PERFECT SOLUTION\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1101: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE using deep neural network propensity scores: -0.7958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Fit deep neural network\n",
    "nn = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, early_stopping=True)\n",
    "nn.fit(X, t)\n",
    "\n",
    "# Estimate propensity scores\n",
    "p_score_nn = nn.predict_proba(X)[:, 1]\n",
    "\n",
    "# Estimate ATE using propensity scores\n",
    "ate_nn = np.mean((t * y) / p_score_nn) - np.mean(((1 - t) * y) / (1 - p_score_nn))\n",
    "print(f\"ATE using deep neural network propensity scores: {ate_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative ATE value suggests that, on average, the treatment has a negative effect on the outcome variable compared to the control group (no treatment).\n",
    "Here's an interpretation of these results:\n",
    "\n",
    "ATE using logistic regression propensity scores: -1.5174\n",
    "\n",
    "The estimated ATE using logistic regression propensity scores is -1.5174.\n",
    "This means that, on average, the treatment reduces the outcome variable by approximately 1.5174 units compared to the control group, after accounting for the confounding variables (x0, x1, x2, x3).\n",
    "A negative ATE implies that the treatment has a harmful or undesirable effect on the outcome variable.\n",
    "\n",
    "\n",
    "ATE using deep neural network propensity scores: -0.7958\n",
    "\n",
    "The estimated ATE using the deep neural network propensity scores is -0.7958.\n",
    "This means that, on average, the treatment reduces the outcome variable by approximately 0.7958 units compared to the control group, after accounting for the confounding variables (x0, x1, x2, x3).\n",
    "The magnitude of the negative ATE is smaller compared to the logistic regression approach, suggesting a less severe negative effect of the treatment on the outcome variable.\n",
    "\n",
    "Comparing the two ATE estimates:\n",
    "\n",
    "Both methods suggest a negative effect of the treatment on the outcome variable, but the deep neural network approach estimates a smaller negative effect (-0.7958) compared to the logistic regression approach (-1.5174).\n",
    "\n",
    "Deep neural networks can potentially model more complex non-linear relationships, which might lead to a better estimation of the propensity scores and, consequently, a different ATE estimate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
